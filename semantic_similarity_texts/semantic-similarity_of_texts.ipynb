{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "gloveFile = \"data\\\\glove.6B.50d.txt\"\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    \n",
    "    # open glove file and read its contents\n",
    "    with open(gloveFile, encoding=\"utf8\" ) as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # initialise dictionalry model\n",
    "    model = {}\n",
    "    for line in content:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "model = loadGloveModel(gloveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess(raw_text):\n",
    "\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n",
    "    \n",
    "    return cleaned_words\n",
    "\n",
    "def cosine_distance_wordembedding_method(s1, s2):\n",
    "    \n",
    "    vector_1 = np.mean([model[word] for word in preprocess(s1)],axis=0)\n",
    "    vector_2 = np.mean([model[word] for word in preprocess(s2)],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    #print(round((1-cosine)*100,2),'%')\n",
    "    return round((1-cosine)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.12\n"
     ]
    }
   ],
   "source": [
    "# example for semantic similarity\n",
    "a1='his house has better goods'\n",
    "a2='he got some good products in his home'\n",
    "print(cosine_distance_wordembedding_method(a1, a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. she is combing her hair matches with :\n",
      "         she is brushing her hair : 81.23\n",
      "\n",
      "2. she is brushing her hair matches with :\n",
      "         she is combing her hair : 81.23\n",
      "         she is eating her food : 50.2\n",
      "\n",
      "3. she is eating her food matches with :\n",
      "         she is brushing her hair : 50.2\n",
      "         he came for dinner tonight : 53.73\n",
      "         he spoke to her about dinner : 51.45\n",
      "\n",
      "4. he came for dinner tonight matches with :\n",
      "         she is eating her food : 53.73\n",
      "         he spoke to her about dinner : 84.3\n",
      "         teacher spoke to him : 58.56\n",
      "         science is the key for the future : 53.82\n",
      "\n",
      "5. he spoke to her about dinner matches with :\n",
      "         she is eating her food : 51.45\n",
      "         he came for dinner tonight : 84.3\n",
      "         teacher spoke to him : 77.18\n",
      "\n",
      "6. teacher spoke to him matches with :\n",
      "         he came for dinner tonight : 58.56\n",
      "         he spoke to her about dinner : 77.18\n",
      "         he teaches science : 63.88\n",
      "         science is the key for the future : 57.57\n",
      "\n",
      "7. he teaches science matches with :\n",
      "         teacher spoke to him : 63.88\n",
      "         science is the key for the future : 72.65\n",
      "\n",
      "8. science is the key for the future matches with :\n",
      "         he came for dinner tonight : 53.82\n",
      "         teacher spoke to him : 57.57\n",
      "         he teaches science : 72.65\n",
      "         he can predict the future : 78.25\n",
      "         he designed prediction algorithm : 60.1\n",
      "\n",
      "9. he can predict the future matches with :\n",
      "         science is the key for the future : 78.25\n",
      "         he designed prediction algorithm : 58.89\n",
      "\n",
      "10. he designed prediction algorithm matches with :\n",
      "         science is the key for the future : 60.1\n",
      "         he can predict the future : 58.89\n",
      "\n",
      "first method : uniq sentence\n",
      "      he designed prediction algorithm\n",
      "\n",
      "second method : top uniq sentences\n",
      "       he spoke to her about dinner 6.96\n",
      "       he designed prediction algorithm 6.96\n",
      "       she is brushing her hair 11.73\n",
      "       he designed prediction algorithm 11.73\n",
      "       she is brushing her hair 12.29\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# another method to input sentences  \n",
    "\n",
    "n=int(input(\"enter the number of sentences\"))\n",
    "sentences_list=[]\n",
    "for i in range(0,n):\n",
    "    sentences_list.append(input(f\"enter the {i}th sentence \"))\n",
    "'''\n",
    "\n",
    "# input texts\n",
    "s1 = 'she is combing her hair'\n",
    "s2 = 'she is brushing her hair'\n",
    "s3 = 'she is eating her food'\n",
    "s4 = 'he came for dinner tonight'\n",
    "s5 = 'he spoke to her about dinner'\n",
    "s6 = 'teacher spoke to him'\n",
    "s7 = 'he teaches science'\n",
    "s8 = 'science is the key for the future'\n",
    "s9 = 'he can predict the future'\n",
    "s10 = 'he designed prediction algorithm'\n",
    "\n",
    "# create list of texts\n",
    "l=[]\n",
    "l.append(s1)\n",
    "l.append(s2)\n",
    "l.append(s3)\n",
    "l.append(s4)\n",
    "l.append(s5)\n",
    "l.append(s6)\n",
    "l.append(s7)\n",
    "l.append(s8)\n",
    "l.append(s9)\n",
    "l.append(s10)\n",
    "\n",
    "# list to add pairs of text to compare\n",
    "li=[]\n",
    "# list to add sum of similarity value for each text\n",
    "sum2=[]\n",
    "\n",
    "for i in l:\n",
    "    sum1=0\n",
    "    for j in l:\n",
    "       \n",
    "        # calculating similarity between two texts\n",
    "        score=cosine_distance_wordembedding_method(i, j)\n",
    "\n",
    "        z=[]\n",
    "        z.append(i)\n",
    "        z.append(j)\n",
    "        z.append(score)\n",
    "\n",
    "        # list of triplets of text1 , text2 and similarity value of both texts\n",
    "        li.append(z)\n",
    "        sum1+=score\n",
    "    \n",
    "    # calculating average\n",
    "    sum2.append(sum1/10)\n",
    "\n",
    "for s in range(0,10):\n",
    "    \n",
    "    # prints text with similar text of its group\n",
    "    print(f\"{s+1}. {l[s]} matches with :\")\n",
    "    for t in li:\n",
    "        if t[0]==l[s]:\n",
    "            # thershold similarity value \n",
    "            r=50\n",
    "            if t[2] >= r and t[2]!=100:\n",
    "                print('        ',t[1],':',t[2])\n",
    "    print(\"\")\n",
    "                \n",
    "\n",
    "# to fetch the lowest average value \n",
    "su=sorted(sum2)\n",
    "low=su[0]\n",
    "ind=sum2.index(low)\n",
    "\n",
    "# printing unique sentence based on lowest average value of similarity\n",
    "print('first method : unique sentence')\n",
    "print('      ',l[ind])\n",
    "print(\"\")\n",
    "        \n",
    "        \n",
    "# printing top unique sentences based on lowest value of similarity of each text\n",
    "less=[]\n",
    "for i in li:\n",
    "    less.append(i[2])\n",
    "less.sort()\n",
    "less=sorted(li,key=lambda l:l[2], reverse=False)\n",
    "print('second method : top uniq sentences')\n",
    "for o in range(0,5):\n",
    "    print('      ',less[o][0],less[o][2])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
